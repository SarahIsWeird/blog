---
title: Artificial intelligence isn't intelligent
draft: true
---

# Artificial intelligence isn't intelligent

I was watching a video by Kyle Hill called
[Dead Internet Theory: A.I. Killed the Internet](https://www.youtube.com/watch?v=PaVjQFMg7L0) today. To summarize his
video very quickly, there is a theory that the internet is actually mostly bots, not humans anymore. Go watch it, it's a
great video.

But watching it brought up some thoughts I had about artificial intelligence in the past. Every day, we seem to wake up
to new headlines about some new AI breakthrough, mishap or warning by some expert. And yet, most articles share a common
sentiment:

***AI is intelligent.***[^1][^2][^3][^4]

... *What?* It absolutely is **not**. It may be cool, it has its uses, but it
won't improve our lives, won't destroy all humanity, and it also
[won't save education](https://www.ted.com/talks/sal_khan_how_ai_could_save_not_destroy_education). Okay, a minor
tangent. Look at 04:05. Sal Khan, the founder of Khan Academy, can't teach his kids why not telling the computer to do
something results in the computer not doing it? I get that it can be confusing for novices, but that's something that
should be very easy to explain for someone who built an entire online academy platform.

This "tangent" is actually pretty related to the point I want to make. AI is not the be all end all solution for any
problem that might come up. What Sal Khan did is amazing work, he created a free platform where children can learn and
practice. But charging four bucks per month for something that has a solid chance of "hallucinating" answers is a bit
weird to me.

## "Hallucinations", or rather, being wrong

Hallucination is the term given for wrong results given by an AI. Basically, the AI "hallucinated" the answer. The
picture below is an example of a hallucination:

<img src="/img/en/ai-is-not-intelligent/ai-handshake.png"
     alt="AI generated image of two hands shaking. A third arm is visible, one hand is too large and the fingers are a jumbled mess."
     width="500" />

Okay, a layman wouldn't call that a hallucination, would they? They'd call it *wrong*, and on so many levels at that.
The prompt was "two hands shaking", but there's a third arm present. Also, the left hand looks like it has six fingers,
just that one was replaced by a demonic mess of finger joints. I chose a hard example on purpose, AI is notorious for
struggling with hand anatomy. Photos don't show every hand in the same position, rotation and pose. As humans, we can
see a photo of hands shaking, and think, "Yep, those sure are two hands shaking!" But an AI doesn't think. It analyses
patterns, so it analyses the fact that the word "hand" carries the connotation of a palm and fingers. The fingers stick
out from the palm. Also, the fingers have three segments. But sometimes it only has two. Or a finger is missing. Or
all the fingers are missing. Sometimes the fingernails are missing as well. The numbers inside the AI are tuned in such
a way that it produces a similar result. But the numbers can't think. They aren't intelligent. They don't realise that
the reason fingernails can be missing is that the hand is turned over. Or that fingers are missing because the person
made a fist. Or that the fingers are curled. Or that for some people, a finger *can* actually be missing. This nuance is
wholly lost on the AI.

In my opinion, the name "hallucination" downplays the issue. AI models aren't foolproof. How are they supposed to be? We
can only sensibly train them on human-made creations, and those are all over the place. If humans made the training
material, some of that contains errors, and AI has to learn from it, how is it supposed to not be *wrong*?

You can clearly see this with chat AIs. Look at this conversation I had with
[Gemini by Google](https://gemini.google.com). I asked it, "Do pigs have wings?" And I got the answer,
"No, pigs don't have wings." Okay, so far so good. So what's the issue?

<img src="/img/en/ai-is-not-intelligent/pig-wings.png"
     alt="Gemini's response: No, pigs don't have wings. Pigs are mammals, and mammals don't have wings. They have four legs for walking and a tail instead."
     width="700" />

So, no mammals have wings? What about bats? Mammals have four legs? What about... bats, or even humans? And while humans
have a tail*bone*, we don't have a tail, similar to gorillas. You might say that this is nitpicking, but I believe that
giving black-and-white answers isn't a good thing. The world simply doesn't work that way. This is the reason that
"humans have tails" is *almost* true. It's not, but there is a kernel of truth to it. An experienced author can present
this kernel alongside the norm, so that even a scientifically inexperienced reader understands it. Gemini didn't do any
of this. It told me something that's true *for the most part*, but if you look at some popular definition, it's not
actually included in any of those.[^5] It's just something that happens to be the case for most mammals. It even went so
far to highlight the phrase with green, to signify "probably true". But being probable and being true are two wholly
different things.

So, let's think about this for a moment. An AI, touted by Google to help me learn, didn't actually help me achieve my
goal, because it hallucinated some half-truth. Imagine I'm nine years old, sitting in my room and studying for my
upcoming biology test. Since my parents think that AI is awesome, they don't help me themselves. Instead, they give me
a laptop with Gemini opened. Let's also assume my nine-year-old self wouldn't instantly close it and open YouTube
instead. So I'm sitting there, my mind wanders away from the biology test, and I think to myself, "Maybe some pigs have
wings! :O" Since I have this cool thing that knows everything in front of me, I punch in my question, probably with some
spelling errors at that. I get the response that mammals don't have wings, but have four legs and a tail. Oh cool, what
a nice shortcut to ace the test! I'll just memorise that, and then I can finally go play Minecraft. But what would
nine-year-old me now think? She'd think that lizards are mammals, while humans, bats and whales are not. And as a
result, she'd fail the test.

Okay, it's a pretty tame example. But now remember that people search for news using search
engines, and that many of them are starting to integrate AI into the results. Suddenly the AI might hallucinate that
the person that shot Donald Trump was Joe Biden himself.

## AI and politics

Misinformation campaigns are becoming worse than ever before. And while their intended target are people, another side
effect is AI. 

[^1]: ZDNET: [What is AI? Everything to know about artificial intelligence](https://www.zdnet.com/article/what-is-ai-heres-everything-you-need-to-know-about-artificial-intelligence/)
    June 5, 2024 ([WayBack](https://web.archive.org/web/20240722133526/https://www.zdnet.com/article/what-is-ai-heres-everything-you-need-to-know-about-artificial-intelligence/))
[^2]: BBC: [What is AI, how does it work and what can it be used for?](https://www.bbc.com/news/technology-65855333)
    May 13, 2024 ([WayBack](https://web.archive.org/web/20240722133650/https://www.bbc.com/news/technology-65855333))
[^3]: builtin: [What AI is, why it matters, how it works](https://builtin.com/artificial-intelligence)
    April 2, 2024 ([WayBack](https://web.archive.org/web/20240722135427/https://builtin.com/artificial-intelligence))
[^4]: Live Science: [What is artificial intelligence (AI)?](https://www.livescience.com/technology/artificial-intelligence/what-is-artificial-intelligence-ai)
    April 14, 2024 ([WayBack](https://web.archive.org/web/20240722135622/https://www.livescience.com/technology/artificial-intelligence/what-is-artificial-intelligence-ai))
[^5]: Wikipedia: [Mammal. Classification](https://en.wikipedia.org/wiki/Mammal#Classification)
    July 22, 2024 ([WayBack](https://web.archive.org/web/20240722210222/https://en.wikipedia.org/wiki/Mammal#Classification))
[^6]: WaPo: [A week of nonstop breaking political news stumps AI chatbots](https://www.msn.com/en-us/news/technology/a-week-of-nonstop-breaking-political-news-stumps-ai-chatbots/ar-BB1qpqYZ)
July 22, 2024 ([WayBack](https://web.archive.org/web/20240722144343/https://www.msn.com/en-us/news/technology/a-week-of-nonstop-breaking-political-news-stumps-ai-chatbots/ar-BB1qpqYZ))
